{
  "components": {
    "comp-condition-1": {
      "dag": {
        "tasks": {
          "deploy-to-endpoint": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-deploy-to-endpoint"
            },
            "dependentTasks": [
              "upload-model"
            ],
            "inputs": {
              "parameters": {
                "endpoint_display_name": {
                  "componentInputParameter": "pipelinechannel--endpoint_display_name"
                },
                "location": {
                  "runtimeValue": {
                    "constant": "europe-west1"
                  }
                },
                "model_name": {
                  "componentInputParameter": "pipelinechannel--model_name"
                },
                "model_resource_name": {
                  "taskOutputParameter": {
                    "outputParameterKey": "resource_name",
                    "producerTask": "upload-model"
                  }
                },
                "project_id": {
                  "runtimeValue": {
                    "constant": "hcred-vertexai"
                  }
                }
              }
            },
            "taskInfo": {
              "name": "deploy-to-endpoint"
            }
          },
          "upload-model": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-upload-model"
            },
            "inputs": {
              "artifacts": {
                "model": {
                  "componentInputArtifact": "pipelinechannel--model-train-model"
                }
              },
              "parameters": {
                "default": {
                  "componentInputParameter": "pipelinechannel--force_default"
                },
                "model_description": {
                  "componentInputParameter": "pipelinechannel--model_description"
                },
                "model_name": {
                  "componentInputParameter": "pipelinechannel--model_name"
                },
                "project_id": {
                  "runtimeValue": {
                    "constant": "hcred-vertexai"
                  }
                },
                "region": {
                  "runtimeValue": {
                    "constant": "europe-west1"
                  }
                },
                "run": {
                  "runtimeValue": {
                    "constant": "{{$.pipeline_job_name}}"
                  }
                },
                "run_id": {
                  "runtimeValue": {
                    "constant": "{{$.pipeline_job_uuid}}"
                  }
                },
                "serving_image": {
                  "componentInputParameter": "pipelinechannel--serving_container_image_uri"
                }
              }
            },
            "taskInfo": {
              "name": "upload-model"
            }
          }
        }
      },
      "inputDefinitions": {
        "artifacts": {
          "pipelinechannel--model-train-model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "pipelinechannel--endpoint_display_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--force_default": {
            "parameterType": "BOOLEAN"
          },
          "pipelinechannel--model-evaluate-upload_model": {
            "parameterType": "STRING"
          },
          "pipelinechannel--model_description": {
            "parameterType": "STRING"
          },
          "pipelinechannel--model_name": {
            "parameterType": "STRING"
          },
          "pipelinechannel--serving_container_image_uri": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-deploy-to-endpoint": {
      "executorLabel": "exec-deploy-to-endpoint",
      "inputDefinitions": {
        "parameters": {
          "endpoint_display_name": {
            "parameterType": "STRING"
          },
          "location": {
            "defaultValue": "europe-west1",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "model_name": {
            "parameterType": "STRING"
          },
          "model_resource_name": {
            "parameterType": "STRING"
          },
          "project_id": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-load-bq-dataset": {
      "executorLabel": "exec-load-bq-dataset",
      "inputDefinitions": {
        "parameters": {
          "bq_dataset": {
            "parameterType": "STRING"
          },
          "project_id": {
            "parameterType": "STRING"
          },
          "seed": {
            "defaultValue": 42.0,
            "isOptional": true,
            "parameterType": "NUMBER_INTEGER"
          },
          "test_size": {
            "defaultValue": 0.15,
            "isOptional": true,
            "parameterType": "NUMBER_DOUBLE"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "dataset_train": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          },
          "dataset_val": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-model-evaluate": {
      "executorLabel": "exec-model-evaluate",
      "inputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          },
          "val_set": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "target_col": {
            "parameterType": "STRING"
          },
          "upload_model": {
            "defaultValue": false,
            "isOptional": true,
            "parameterType": "BOOLEAN"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "metrics": {
            "artifactType": {
              "schemaTitle": "system.Metrics",
              "schemaVersion": "0.0.1"
            }
          },
          "metrics_cls": {
            "artifactType": {
              "schemaTitle": "system.ClassificationMetrics",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "upload_model": {
            "parameterType": "STRING"
          }
        }
      }
    },
    "comp-model-train": {
      "executorLabel": "exec-model-train",
      "inputDefinitions": {
        "artifacts": {
          "train_set": {
            "artifactType": {
              "schemaTitle": "system.Dataset",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "model_name": {
            "parameterType": "STRING"
          },
          "model_params": {
            "isOptional": true,
            "parameterType": "STRUCT"
          },
          "serving_container_image_uri": {
            "parameterType": "STRING"
          },
          "target_col": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        }
      }
    },
    "comp-upload-model": {
      "executorLabel": "exec-upload-model",
      "inputDefinitions": {
        "artifacts": {
          "model": {
            "artifactType": {
              "schemaTitle": "system.Model",
              "schemaVersion": "0.0.1"
            }
          }
        },
        "parameters": {
          "default": {
            "defaultValue": false,
            "isOptional": true,
            "parameterType": "BOOLEAN"
          },
          "model_description": {
            "parameterType": "STRING"
          },
          "model_name": {
            "parameterType": "STRING"
          },
          "project_id": {
            "parameterType": "STRING"
          },
          "region": {
            "defaultValue": "europe-west1",
            "isOptional": true,
            "parameterType": "STRING"
          },
          "run": {
            "parameterType": "STRING"
          },
          "run_id": {
            "parameterType": "STRING"
          },
          "serving_image": {
            "parameterType": "STRING"
          }
        }
      },
      "outputDefinitions": {
        "parameters": {
          "resource_name": {
            "parameterType": "STRING"
          }
        }
      }
    }
  },
  "defaultPipelineRoot": "gs://training_data_hcred-vertexai/pipeline-output/",
  "deploymentSpec": {
    "executors": {
      "exec-deploy-to-endpoint": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "deploy_to_endpoint"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google.cloud.aiplatform' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef deploy_to_endpoint(\n    # model: Input[Artifact],\n    model_name: str,\n    model_resource_name: str,\n    endpoint_display_name: str,\n    project_id: str,\n    location: str = 'europe-west1',\n):\n    # from google_cloud_pipeline_components.v1.endpoint import ModelDeployOp, EndpointCreateOp\n    import google.cloud.aiplatform as aip\n    import logging\n\n    logging.info(f\"Deploy model\")\n    aip.init(project=project_id, location=location)\n\n    target_endpoint = None\n    for endpoint in aip.Endpoint.list(order_by=\"update_time desc\"):\n        if endpoint.display_name == endpoint_display_name:\n            target_endpoint = endpoint\n\n    if target_endpoint is None:\n        target_endpoint = aip.Endpoint.create(\n            project=project_id,\n            display_name=endpoint_display_name,\n            location=location,\n        )\n        logging.info(f\"Created new endpoint: {target_endpoint.display_name}\")\n    else:\n        logging.info(f\"Using existing endpoint: {endpoint.display_name}\")\n\n    # model.resource_name = \"test\"\n    # logging.info(f\"dir: {dir(model)}\")\n    # logging.info(f\"model: {model}\")\n    # logging.info(f\"model.resource_name (deploy): {model.resource_name}\")\n    model = aip.Model(model_name=model_resource_name)\n    target_endpoint.deploy(\n        model=model,\n        deployed_model_display_name=model_name,\n        min_replica_count=1,\n        max_replica_count=1,\n        machine_type='n1-standard-4', \n        traffic_split={\"0\": 100},\n    )\n\n    # model.deploy(\n    #     endpoint=target_endpoint,\n    #     deployed_model_display_name=model_name,\n    #     # traffic_percentage=traffic_percentage,\n    #     traffic_split={\"0\": 100},\n    #     machine_type='n1-standard-4',\n    #     min_replica_count=1,\n    #     max_replica_count=4,\n    #     # explanation_metadata=explanation_metadata,\n    #     # explanation_parameters=explanation_parameters,\n    #     # metadata=metadata,\n    #     # sync=sync,\n    # )\n\n    # model.wait()\n\n    # print(model.display_name)\n    # print(model.resource_name)\n\n    # deployed_model = model.deploy(\n    #     endpoint=endpoint,\n    #     deployed_model_display_name=model_name,\n    #     machine_type=\"n1-standard-4\",\n    #     min_replica_count=1,\n    #     max_replica_count=1,\n    #     traffic_split={\"0\": 100}\n    # )\n    # ModelDeployOp(\n    #     endpoint=target_endpoint,\n    #     model=model,\n    #     deployed_model_display_name=model_name,\n    #     dedicated_resources_machine_type=\"n1-standard-4\",\n    #     dedicated_resources_min_replica_count=1,\n    # )\n\n    logging.info(f\"Model deployed to endpoint: {endpoint.display_name}\")\n\n"
          ],
          "image": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest"
        }
      },
      "exec-load-bq-dataset": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "load_bq_dataset"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google-cloud-bigquery[all]' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef load_bq_dataset(\n    project_id: str,\n    bq_dataset: str,\n    dataset_train: Output[Dataset],\n    # dataset_test: Output[Dataset],\n    dataset_val: Output[Dataset],\n    test_size: float = 0.15,\n    seed: int = 42,\n):\n    from google.cloud import bigquery\n    from sklearn.model_selection import train_test_split\n    import logging\n\n    training_query = f\"\"\"\n        SELECT * FROM `{project_id}.{bq_dataset}.train_base` as tb\n        LEFT JOIN `{project_id}.{bq_dataset}.train_static_0` as ts ON tb.case_id = ts.case_id\n        LEFT JOIN `{project_id}.{bq_dataset}.train_static_cb_0` as tscb ON ts.case_id = tscb.case_id\n    \"\"\"\n\n    logging.info(f\"Pulling data from {bq_dataset}\")\n    client = bigquery.Client(project=project_id)\n    full_train_query = client.query(training_query)\n    logging.info(\"bQuery completed\")\n    full_train_df = full_train_query.to_dataframe()\n    logging.info(\"bQuery to dataframe completed\")\n\n    train_df, val_df = train_test_split(full_train_df, random_state=seed, test_size=test_size)\n    # val_df, test_df = train_test_split(test_df, random_state=seed, test_size=0.5)\n\n    train_df.to_parquet(dataset_train.path, index=False)\n    logging.info(\"train_df save completed\")\n    val_df.to_parquet(dataset_val.path, index=False)\n    logging.info(\"val_df save completed\")\n    # test_df.to_parquet(dataset_test.path, index=False)\n    # logging.info(\"test_df save completed\")\n\n"
          ],
          "image": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest"
        }
      },
      "exec-model-evaluate": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "model_evaluate"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pyarrow' 'category_encoders' 'dill' 'google.cloud.aiplatform' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef model_evaluate(\n    target_col: str,\n    # project_id: str,\n    # location: str,\n    # model_name: str,\n    val_set: Input[Dataset],\n    model: Input[Model],\n    metrics_cls: Output[ClassificationMetrics],\n    metrics: Output[Metrics],\n    upload_model: bool = False\n) -> NamedTuple(\"output\", [(\"upload_model\", str)]): # type: ignore\n\n    import google.cloud.aiplatform as aip\n    import pandas as pd\n    from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n    import logging\n    import dill\n\n    logging.info(\"Reading data...\")\n    val_df = pd.read_parquet(val_set.path)\n    X = val_df.drop(columns=[target_col])\n    y = val_df[target_col]\n\n    logging.info(\"Reading model...\")\n    logging.info(f\"model_path: {model.path}\")\n    dill.settings['recurse'] = True\n    with open(model.path, 'rb') as file:\n        model_pipeline = dill.load(\n            file=file,\n        )\n\n    logging.info(\"Evaluating model...\")\n    all_feats = list(model_pipeline[4].get_feature_names_out())\n    X = X[all_feats]\n    X_2 = X.copy()\n\n    y_scores = model_pipeline.predict_proba(X_2)[:, 1]\n    y_pred = model_pipeline.predict(X)\n\n    # roc_auc_score\n    roc_auc = roc_auc_score(y, y_pred)\n    metrics.log_metric(\"roc_auc\", float(roc_auc))\n    logging.info(f\"roc_auc: {float(roc_auc)}\")\n\n    # accuracy_score\n    accuracy = accuracy_score(y, y_pred)\n    metrics.log_metric(\"accuracy\", float(accuracy))\n    logging.info(f\"accuracy: {float(accuracy)}\")\n\n    # roc_curve\n    fpr, tpr, thresholds = roc_curve(y_true=y, y_score=y_scores, pos_label=True)\n    # metrics_cls.log_roc_curve(fpr.tolist()[0::30], tpr.tolist()[0::30], thresholds.tolist()[0::30])\n    logging.info(f\"log_roc_curve: {fpr.tolist()[0:10]}\")\n\n    # confusion_matrix\n    metrics_cls.log_confusion_matrix(\n        [\"False\", \"True\"],\n        confusion_matrix(y, y_pred).tolist(),\n    )\n    logging.info(f\"confusion_matrix\")\n\n    # aip.init(project=project_id, location=location)\n    # previous_model = aip.Model.list(filter=f'display_name=\"{model_name}\"', location=location)[0]\n    # logging.info(f\"list_model_evaluations: {previous_model.list_model_evaluations()}\")\n    # logging.info(f\"previous_model: {dir(previous_model)}\")\n    # logging.info(f\"versioning_registry: {previous_model.versioning_registry}\")\n    # previous_model.evaluate\n    # model_registry = aiplatform.models.ModelRegistry(model=model_id)\n    # versions = model_registry.list_versions()\n\n    if upload_model:\n        upload_model = \"true\"\n    else:\n        upload_model = \"false\"\n    return upload_model,\n\n"
          ],
          "image": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest"
        }
      },
      "exec-model-train": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "model_train"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'pyarrow' 'category_encoders' 'dill' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef model_train(\n    model_name:str,\n    target_col: str,\n    train_set: Input[Dataset],\n    model: Output[Model],\n    serving_container_image_uri: str,\n    model_params: dict = None,\n):\n    from sklearn.pipeline import Pipeline\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.base import BaseEstimator, TransformerMixin\n    from  category_encoders import CatBoostEncoder\n    from pathlib import Path\n    import pandas as pd\n    import numpy as np    \n    import warnings\n    import logging\n    import gc\n\n    if model_params is None:\n        model_params = {}\n\n    ### Features\n    #region\n    NUMERICAL_FEATURES = [\n        'MONTH',\n        'WEEK_NUM',\n        'actualdpdtolerance_344P',\n        'amtinstpaidbefduel24m_4187115A',\n        'annuity_780A',\n        'annuitynextmonth_57A',\n        'applicationcnt_361L',\n        'applications30d_658L',\n        'applicationscnt_1086L',\n        'applicationscnt_464L',\n        'applicationscnt_629L',\n        'applicationscnt_867L',\n        'avgdbddpdlast24m_3658932P',\n        'avgdbddpdlast3m_4187120P',\n        'avgdbdtollast24m_4525197P',\n        'avgdpdtolclosure24_3658938P',\n        'avginstallast24m_3658937A',\n        'avglnamtstart24m_4525187A',\n        'avgmaxdpdlast9m_3716943P',\n        'avgoutstandbalancel6m_4187114A',\n        'avgpmtlast12m_4525200A',\n        'clientscnt12m_3712952L',\n        'clientscnt3m_3712950L',\n        'clientscnt6m_3712949L',\n        'clientscnt_100L',\n        'clientscnt_1022L',\n        'clientscnt_1071L',\n        'clientscnt_1130L',\n        'clientscnt_136L',\n        'clientscnt_157L',\n        'clientscnt_257L',\n        'clientscnt_304L',\n        'clientscnt_360L',\n        'clientscnt_493L',\n        'clientscnt_533L',\n        'clientscnt_887L',\n        'clientscnt_946L',\n        'cntincpaycont9m_3716944L',\n        'cntpmts24_3658933L',\n        'commnoinclast6m_3546845L',\n        'credamount_770A',\n        'currdebt_22A',\n        'currdebtcredtyperange_828A',\n        'daysoverduetolerancedd_3976961L',\n        'deferredmnthsnum_166L',\n        'disbursedcredamount_1113A',\n        'downpmt_116A',\n        'eir_270L',\n        'homephncnt_628L',\n        'inittransactionamount_650A',\n        'interestrate_311L',\n        'interestrategrace_34L',\n        'lastapprcredamount_781A',\n        'lastdependentsnum_448L',\n        'lastotherinc_902A',\n        'lastotherlnsexpense_631A',\n        'lastrejectcredamount_222A',\n        'maininc_215A',\n        'mastercontrelectronic_519L',\n        'mastercontrexist_109L',\n        'maxannuity_159A',\n        'maxannuity_4075009A',\n        'maxdbddpdlast1m_3658939P',\n        'maxdbddpdtollast12m_3658940P',\n        'maxdbddpdtollast6m_4187119P',\n        'maxdebt4_972A',\n        'maxdpdfrom6mto36m_3546853P',\n        'maxdpdinstlnum_3546846P',\n        'maxdpdlast12m_727P',\n        'maxdpdlast24m_143P',\n        'maxdpdlast3m_392P',\n        'maxdpdlast6m_474P',\n        'maxdpdlast9m_1059P',\n        'maxdpdtolerance_374P',\n        'maxinstallast24m_3658928A',\n        'maxlnamtstart6m_4525199A',\n        'maxoutstandbalancel12m_4187113A',\n        'maxpmtlast3m_4525190A',\n        'mindbddpdlast24m_3658935P',\n        'mindbdtollast24m_4525191P',\n        'mobilephncnt_593L',\n        'monthsannuity_845L',\n        'numactivecreds_622L',\n        'numactivecredschannel_414L',\n        'numactiverelcontr_750L',\n        'numcontrs3months_479L',\n        'numincomingpmts_3546848L',\n        'numinstlallpaidearly3d_817L',\n        'numinstls_657L',\n        'numinstlsallpaid_934L',\n        'numinstlswithdpd10_728L',\n        'numinstlswithdpd5_4187116L',\n        'numinstlswithoutdpd_562L',\n        'numinstmatpaidtearly2d_4499204L',\n        'numinstpaid_4499208L',\n        'numinstpaidearly3d_3546850L',\n        'numinstpaidearly3dest_4493216L',\n        'numinstpaidearly5d_1087L',\n        'numinstpaidearly5dest_4493211L',\n        'numinstpaidearly5dobd_4499205L',\n        'numinstpaidearly_338L',\n        'numinstpaidearlyest_4493214L',\n        'numinstpaidlastcontr_4325080L',\n        'numinstpaidlate1d_3546852L',\n        'numinstregularpaid_973L',\n        'numinstregularpaidest_4493210L',\n        'numinsttopaygr_769L',\n        'numinsttopaygrest_4493213L',\n        'numinstunpaidmax_3546851L',\n        'numinstunpaidmaxest_4493212L',\n        'numnotactivated_1143L',\n        'numpmtchanneldd_318L',\n        'numrejects9m_859L',\n        'pctinstlsallpaidearl3d_427L',\n        'pctinstlsallpaidlat10d_839L',\n        'pctinstlsallpaidlate1d_3546856L',\n        'pctinstlsallpaidlate4d_3546849L',\n        'pctinstlsallpaidlate6d_3546844L',\n        'pmtnum_254L',\n        'posfpd10lastmonth_333P',\n        'posfpd30lastmonth_3976960P',\n        'posfstqpd30lastmonth_3976962P',\n        'price_1097A',\n        'sellerplacecnt_915L',\n        'sellerplacescnt_216L',\n        'sumoutstandtotal_3546847A',\n        'sumoutstandtotalest_4493215A',\n        'totaldebt_9A',\n        'totalsettled_863A',\n        'totinstallast1m_4525188A',\n        'contractssum_5085716L',\n        'days120_123L',\n        'days180_256L',\n        'days30_165L',\n        'days360_512L',\n        'days90_310L',\n        'firstquarter_103L',\n        'for3years_128L',\n        'for3years_504L',\n        'for3years_584L',\n        'formonth_118L',\n        'formonth_206L',\n        'formonth_535L',\n        'forquarter_1017L',\n        'forquarter_462L',\n        'forquarter_634L',\n        'fortoday_1092L',\n        'forweek_1077L',\n        'forweek_528L',\n        'forweek_601L',\n        'foryear_618L',\n        'foryear_818L',\n        'foryear_850L',\n        'fourthquarter_440L',\n        'numberofqueries_373L',\n        'pmtaverage_3A',\n        'pmtaverage_4527227A',\n        'pmtaverage_4955615A',\n        'pmtcount_4527229L',\n        'pmtcount_4955617L',\n        'pmtcount_693L',\n        'pmtscount_423L',\n        'pmtssum_45A',\n        'riskassesment_940T',\n        'secondquarter_766L',\n        'thirdquarter_1082L'\n    ]\n    CATEGORICAL_FEATURES = [\n        'bankacctype_710L',\n        'cardtype_51L',\n        'credtype_322L',\n        'disbursementtype_67L',\n        'equalitydataagreement_891L',\n        'equalityempfrom_62L',\n        'inittransactioncode_186L',\n        'isbidproduct_1095L',\n        'isbidproductrequest_292L',\n        'isdebitcard_729L',\n        'lastapprcommoditycat_1041M',\n        'lastapprcommoditytypec_5251766M',\n        'lastcancelreason_561M',\n        'lastrejectcommoditycat_161M',\n        'lastrejectcommodtypec_5251769M',\n        'lastrejectreason_759M',\n        'lastrejectreasonclient_4145040M',\n        'lastst_736L',\n        'opencred_647L',\n        'paytype1st_925L',\n        'paytype_783L',\n        'previouscontdistrict_112M',\n        'twobodfilling_608L',\n        'typesuite_864L',\n        'description_5085714M',\n        'education_1103M',\n        'education_88M',\n        'maritalst_385M',\n        'maritalst_893M',\n        'requesttype_4525192L',\n        'riskassesment_302T'\n    ]\n    DATE_FEATURES = [\n        'date_decision',\n        'datefirstoffer_1144D',\n        'datelastinstal40dpd_247D',\n        'datelastunpaid_3546854D',\n        'dtlastpmtallstes_4499206D',\n        'firstclxcampaign_1125D',\n        'firstdatedue_489D',\n        'lastactivateddate_801D',\n        'lastapplicationdate_877D',\n        'lastapprdate_640D',\n        'lastdelinqdate_224D',\n        'lastrejectdate_50D',\n        'lastrepayingdate_696D',\n        'maxdpdinstldate_3546855D',\n        'validfrom_1069D',\n        'assignmentdate_238D',\n        'assignmentdate_4527235D',\n        'assignmentdate_4955616D',\n        'birthdate_574D',\n        'dateofbirth_337D',\n        'dateofbirth_342D',\n        'responsedate_1012D',\n        'responsedate_4527233D',\n        'responsedate_4917613D',\n        'payvacationpostpone_4187118D',\n    ]\n    #endregion\n\n    ### Preprocessing classes\n    #region\n    #Numerical Imputer\n    class NumericalImputer(BaseEstimator, TransformerMixin):\n        \"\"\"Numerical Data Missing Value Imputer\"\"\"\n        def __init__(self, variables=None):\n                self.variables = variables\n\n        def fit(self, X, y=None):\n            self.imputer_dict_={}\n            for feature in self.variables:\n                self.imputer_dict_[feature] = X[feature].mean()\n            return self\n\n        def transform(self, X):\n            for feature in self.variables:\n                X[feature] = X[feature].fillna(self.imputer_dict_[feature])\n            return X\n\n    class DatesImputer(BaseEstimator, TransformerMixin):\n        \"\"\"Numerical Data Missing Value Imputer\"\"\"\n        def __init__(self, variables=None):\n                self.variables = variables\n\n        def fit(self, X, y=None):\n            self.imputer_dict_={}\n            for feature in self.variables:\n                self.imputer_dict_[feature] = X[feature].mean()\n            return self\n\n        def transform(self,X):\n            for feature in self.variables:\n                X[feature] = X[feature].fillna(self.imputer_dict_[feature])\n            return X\n\n    #Categorical Imputer\n    class CategoricalImputer(BaseEstimator, TransformerMixin):\n        \"\"\"Categorical Data Missing Value Imputer\"\"\"\n        def __init__(self, variables=None):\n            self.variables = variables\n\n        def fit(self, X,y=None):\n            self.imputer_dict_={}\n            for feature in self.variables:\n                self.imputer_dict_[feature] = X[feature].mode()[0]\n            return self\n\n        def transform(self, X):\n            for feature in self.variables:\n                X[feature] = X[feature].fillna(self.imputer_dict_[feature])\n            return X\n\n    class Log1pTransformer(BaseEstimator, TransformerMixin):\n        def __init__(self, num_cols=[], threshold=100):\n            super().__init__()\n            self.num_cols = num_cols\n            self.threshold = threshold\n            self.outliers_cols=[]\n\n        def fit(self, X, y=None):\n            X = X[self.num_cols]\n            with warnings.catch_warnings():\n                warnings.simplefilter(action='ignore', category=RuntimeWarning)\n                X_desc = X.describe()\n            max_to_mean = (\n                np.abs(X_desc.loc['max'] / X_desc.loc['mean'])\n            )\n            min_to_mean = (\n                np.abs(X_desc.loc['min'] / X_desc.loc['mean'])\n            )\n            max_to_mean_finite = max_to_mean[np.isfinite(max_to_mean)]\n            min_to_mean_finite = min_to_mean[np.isfinite(min_to_mean)]\n            outliers_cols_max = list(max_to_mean_finite[max_to_mean_finite > self.threshold].index)\n            outliers_cols_min = list(min_to_mean_finite[min_to_mean_finite > self.threshold].index)\n            self.outliers_cols = outliers_cols_max + outliers_cols_min\n            return self\n\n        def transform(self, X):\n            for col in self.outliers_cols:\n                X[col] = np.log1p(np.abs(X[col])) * np.sign(X[col])\n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            return input_features\n\n    class DateColsTransformer(BaseEstimator, TransformerMixin):\n        \"\"\"Feature Engineering\"\"\"\n        def __init__(self, reference_date_col='date_decision', date_cols=[]):\n            self.date_cols = date_cols\n            self.ref_col = reference_date_col\n\n        def fit(self, X,y=None):\n            return self\n\n        def transform(self, X):\n            X['month_decision'] = X[\"date_decision\"].dt.month.astype('int16')\n            X['weekday_decision'] = X[\"date_decision\"].dt.month.astype('int16')\n            X['day_decision'] = X[\"date_decision\"].dt.month.astype('int16')\n\n            for col_name in self.date_cols:\n                if col_name == 'date_decision':\n                    continue\n                X[col_name] = X[col_name] - X[self.ref_col]\n                X[col_name] = X[col_name].dt.days.astype('int32')\n            X = X.drop(\"date_decision\", axis=1)\n            return X\n\n    class TableDtypesTransformer(BaseEstimator, TransformerMixin):\n        def __init__(self):\n            pass\n\n        def fit(self, X, y=None):\n            return self\n\n        def transform(self, X):\n            for col in X.columns:\n                if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                    X[col] = X[col].astype('int64')\n                elif col in [\"date_decision\"]:\n                    X[col] = pd.to_datetime(X[col])\n                elif col[-1] in (\"P\", \"A\"):\n                    X[col] = X[col].astype('float64')\n                elif col[-1] in (\"M\",) or 'person' in col:\n                    X[col] = X[col].astype('category')\n                elif col[-1] in (\"D\",):\n                    X[col] = pd.to_datetime(X[col])\n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            return input_features\n\n    class DowncastTransformer(BaseEstimator, TransformerMixin):\n        \"\"\"\n        Reduce memory usage of a Pandas DataFrame by converting \n        object types to categories and downcasting numeric columns\n        \"\"\"\n        def __init__(self):\n            pass\n\n        def fit(self, X, y=None):\n            return self\n\n        def transform(self, X):\n            start_mem = X.memory_usage().sum() / 1024**2\n            logging.info('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n            object_cols, int_cols, float_cols = [], [], []\n            for col, dtype in X.dtypes.items():\n                if pd.api.types.is_object_dtype(dtype):\n                    object_cols.append(col)\n                elif pd.api.types.is_integer_dtype(dtype):\n                    int_cols.append(col)\n                elif pd.api.types.is_float_dtype(dtype):\n                    float_cols.append(col)\n            X[object_cols] = X[object_cols].astype('category')\n            X[int_cols] = X[int_cols].apply(pd.to_numeric, downcast='integer')\n            X[float_cols] = X[float_cols].apply(pd.to_numeric, downcast='float')\n\n            end_mem = X.memory_usage().sum() / 1024**2\n            logging.info('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n            logging.info('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            return input_features\n\n    class Debugger(BaseEstimator, TransformerMixin):\n        def __init__(self):\n            pass\n\n        def fit(self, X=None, y=None):\n            return self\n\n        def transform(self, X):\n            logging.info(f\"X.shape: {X.shape}\")\n            logging.info(f\"X type: {type(X)}\")\n            logging.info(f\"inf count: {np.count_nonzero(np.isinf(X))}\")\n            logging.info(f\"nan count: {np.count_nonzero(np.isnan(X))}\")\n            logging.info(f\"nan cols: {X.columns[X.isna().any()].tolist()}\")            \n            return X\n\n        def get_feature_names_out(self, input_features=None):\n            return input_features\n    #endregion\n\n    all_feats = NUMERICAL_FEATURES + CATEGORICAL_FEATURES + DATE_FEATURES\n    train_df = pd.read_parquet(train_set.path)\n    logging.info(\"train_df load completed\")\n    X = train_df[all_feats]\n    y = train_df[target_col]\n\n    del train_df\n    gc.collect()\n\n    model_pipeline = Pipeline(\n        [\n            ('TableDtypes Transformer', TableDtypesTransformer()),\n            ('Downcast Transformer', DowncastTransformer()),\n            ('Numerical Imputer', NumericalImputer(variables=NUMERICAL_FEATURES)),\n            ('Categorical Imputer', CategoricalImputer(variables=CATEGORICAL_FEATURES)),\n            ('Categorical Encoder', CatBoostEncoder(cols=CATEGORICAL_FEATURES)),\n            ('Dates Imputer', DatesImputer(variables=DATE_FEATURES)),\n            ('Dates Transformer', DateColsTransformer(date_cols=DATE_FEATURES)),\n            # ('Debugger', Debugger()),\n            ('Log Transform', Log1pTransformer(num_cols=NUMERICAL_FEATURES)),\n            ('Scaler Transform', MinMaxScaler(copy=False)),\n            ('Linear Model', LogisticRegression(**model_params))\n        ], verbose=True\n    )\n    model_pipeline.fit(X, y)\n    logging.info(\"model fit completed\")\n\n    pickle_output_path = model.path + '.pkl'\n    import dill\n    with open(pickle_output_path, 'wb') as file:\n        dill.dump(\n            obj=model_pipeline,\n            file=file,\n            recurse=True,\n        )\n\n    if model:\n        model.metadata = {\n            \"containerSpec\": {\"imageUri\": serving_container_image_uri},\n            \"framework\": \"scikit-learn\",\n            \"model_name\": model_name,\n            \"model_path\": pickle_output_path,\n        }\n        model.path = pickle_output_path\n\n"
          ],
          "image": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest"
        }
      },
      "exec-upload-model": {
        "container": {
          "args": [
            "--executor_input",
            "{{$}}",
            "--function_to_execute",
            "upload_model"
          ],
          "command": [
            "sh",
            "-c",
            "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0' '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&  python3 -m pip install --quiet --no-warn-script-location 'google.cloud.aiplatform' && \"$0\" \"$@\"\n",
            "sh",
            "-ec",
            "program_path=$(mktemp -d)\n\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n_KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import *\n\ndef upload_model(\n    model: Input[Model],\n    # uploaded_model: Output[Model],\n    model_name: str,\n    serving_image: str,\n    model_description: str,\n    run: str,\n    run_id: str,\n    project_id: str,\n    region: str = 'europe-west1',\n    default: bool = False,\n) -> NamedTuple(\"output\", [(\"resource_name\", str)]): # type: ignore\n    import google.cloud.aiplatform as aip\n    import numpy as np\n    import logging\n\n    logging.info(f\"Upload model for run {run} and run ID {run_id}\")\n\n    parent_model = None\n    models = np.array(aip.Model.list(filter=f'display_name=\"{model_name}\"', location='europe-west1'))\n    if len(models) > 0:\n        update_time = np.array([model.update_time for model in models])\n        parent_model = models[np.argsort(update_time)][-1]\n\n    if parent_model is not None:\n        parent_model = parent_model.resource_name\n        logging.info(f\"Using parent model\")\n        default = True\n    else:\n        default = True\n        logging.info(f\"No parent model\")\n\n    logging.info(f\"model.path: {model.path}\")\n    uploaded_model = aip.Model.upload(\n        project=project_id,\n        location=region,\n        display_name=model_name,\n        artifact_uri='/'.join(model.path.split('/')[:-1]),\n        serving_container_image_uri=serving_image,\n        parent_model=parent_model,\n        is_default_version=default,\n        version_aliases=[\"last-training\"],\n        version_description=model_description,\n    )\n\n    logging.info(f\"uploaded_model.resource_name: {uploaded_model.resource_name}\")\n\n    return uploaded_model.resource_name,\n    # logging.info(f\"model.metadata: {uploaded_model.metadata}\")\n\n    # uploaded_model.metadata['resource_name'] = uploaded_model.resource_name\n    # uploaded_model.resource_name = f'{vertex_model.resource_name}@{vertex_model.version_id}'\n    # uploaded_model.uri = f'https://{region}-aiplatform.googleapis.com/v1/{vertex_model.resource_name}@{vertex_model.version_id}'\n\n"
          ],
          "image": "europe-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-3:latest"
        }
      }
    }
  },
  "pipelineInfo": {
    "name": "gcp-hcred-v1"
  },
  "root": {
    "dag": {
      "outputs": {
        "artifacts": {
          "model-evaluate-metrics": {
            "artifactSelectors": [
              {
                "outputArtifactKey": "metrics",
                "producerSubtask": "model-evaluate"
              }
            ]
          },
          "model-evaluate-metrics_cls": {
            "artifactSelectors": [
              {
                "outputArtifactKey": "metrics_cls",
                "producerSubtask": "model-evaluate"
              }
            ]
          }
        }
      },
      "tasks": {
        "condition-1": {
          "componentRef": {
            "name": "comp-condition-1"
          },
          "dependentTasks": [
            "model-evaluate",
            "model-train"
          ],
          "inputs": {
            "artifacts": {
              "pipelinechannel--model-train-model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "model-train"
                }
              }
            },
            "parameters": {
              "pipelinechannel--endpoint_display_name": {
                "componentInputParameter": "endpoint_display_name"
              },
              "pipelinechannel--force_default": {
                "componentInputParameter": "force_default"
              },
              "pipelinechannel--model-evaluate-upload_model": {
                "taskOutputParameter": {
                  "outputParameterKey": "upload_model",
                  "producerTask": "model-evaluate"
                }
              },
              "pipelinechannel--model_description": {
                "componentInputParameter": "model_description"
              },
              "pipelinechannel--model_name": {
                "componentInputParameter": "model_name"
              },
              "pipelinechannel--serving_container_image_uri": {
                "componentInputParameter": "serving_container_image_uri"
              }
            }
          },
          "taskInfo": {
            "name": "upload-model-condition"
          },
          "triggerPolicy": {
            "condition": "inputs.parameter_values['pipelinechannel--model-evaluate-upload_model'] == 'true'"
          }
        },
        "load-bq-dataset": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-load-bq-dataset"
          },
          "inputs": {
            "parameters": {
              "bq_dataset": {
                "runtimeValue": {
                  "constant": "hcred_train"
                }
              },
              "project_id": {
                "runtimeValue": {
                  "constant": "hcred-vertexai"
                }
              }
            }
          },
          "taskInfo": {
            "name": "load-bq-dataset"
          }
        },
        "model-evaluate": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-model-evaluate"
          },
          "dependentTasks": [
            "load-bq-dataset",
            "model-train"
          ],
          "inputs": {
            "artifacts": {
              "model": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "model",
                  "producerTask": "model-train"
                }
              },
              "val_set": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_val",
                  "producerTask": "load-bq-dataset"
                }
              }
            },
            "parameters": {
              "target_col": {
                "componentInputParameter": "target_col"
              },
              "upload_model": {
                "componentInputParameter": "upload_model"
              }
            }
          },
          "taskInfo": {
            "name": "model-evaluate"
          }
        },
        "model-train": {
          "cachingOptions": {
            "enableCache": true
          },
          "componentRef": {
            "name": "comp-model-train"
          },
          "dependentTasks": [
            "load-bq-dataset"
          ],
          "inputs": {
            "artifacts": {
              "train_set": {
                "taskOutputArtifact": {
                  "outputArtifactKey": "dataset_train",
                  "producerTask": "load-bq-dataset"
                }
              }
            },
            "parameters": {
              "model_name": {
                "componentInputParameter": "model_name"
              },
              "model_params": {
                "componentInputParameter": "model_params"
              },
              "serving_container_image_uri": {
                "componentInputParameter": "serving_container_image_uri"
              },
              "target_col": {
                "componentInputParameter": "target_col"
              }
            }
          },
          "taskInfo": {
            "name": "model-train"
          }
        }
      }
    },
    "inputDefinitions": {
      "parameters": {
        "cols_to_exclude": {
          "isOptional": true,
          "parameterType": "LIST"
        },
        "endpoint_display_name": {
          "parameterType": "STRING"
        },
        "force_default": {
          "defaultValue": false,
          "isOptional": true,
          "parameterType": "BOOLEAN"
        },
        "model_description": {
          "defaultValue": "",
          "isOptional": true,
          "parameterType": "STRING"
        },
        "model_name": {
          "parameterType": "STRING"
        },
        "model_params": {
          "isOptional": true,
          "parameterType": "STRUCT"
        },
        "serving_container_image_uri": {
          "parameterType": "STRING"
        },
        "target_col": {
          "parameterType": "STRING"
        },
        "upload_model": {
          "defaultValue": false,
          "isOptional": true,
          "parameterType": "BOOLEAN"
        }
      }
    },
    "outputDefinitions": {
      "artifacts": {
        "model-evaluate-metrics": {
          "artifactType": {
            "schemaTitle": "system.Metrics",
            "schemaVersion": "0.0.1"
          }
        },
        "model-evaluate-metrics_cls": {
          "artifactType": {
            "schemaTitle": "system.ClassificationMetrics",
            "schemaVersion": "0.0.1"
          }
        }
      }
    }
  },
  "schemaVersion": "2.1.0",
  "sdkVersion": "kfp-2.7.0"
}